{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento del lenguaje natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar usando conda install nltk o pip install nltk\n",
    "import nltk\n",
    "text=\"Bienvenid@s! En este módulo vamos a aprender sobre nlp. \\\n",
    "      Usaremos la biblioteca nltk. A.C.A.M.I.C.A.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bienvenid@s!',\n",
       " 'En este módulo vamos a aprender sobre nlp.',\n",
       " 'Usaremos la biblioteca nltk.',\n",
       " 'A.C.A.M.I.C.A.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PunkSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bienvenid@s!',\n",
       " 'En este módulo vamos a aprender sobre nlp.',\n",
       " 'Usaremos la biblioteca nltk.',\n",
       " 'A.C.A.M.I.C.A.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer=nltk.data.load('tokenizers/punkt/spanish.pickle')\n",
    "\n",
    "tokenizer.tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bienvenid', '@', 's', '!', 'En', 'este', 'módulo', 'vamos', 'a', 'aprender', 'sobre', 'nlp', '.', 'Usaremos', 'la', 'biblioteca', 'nltk', '.', 'A.C.A.M.I.C.A', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text=nltk.word_tokenize(\"Bienvenid@s! En este módulo vamos a aprender sobre nlp. \\\n",
    "      Usaremos la biblioteca nltk. A.C.A.M.I.C.A.\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bienvenid',\n",
       " '@',\n",
       " 's',\n",
       " '!',\n",
       " 'En',\n",
       " 'este',\n",
       " 'módulo',\n",
       " 'vamos',\n",
       " 'a',\n",
       " 'aprender',\n",
       " 'sobre',\n",
       " 'nlp',\n",
       " '.',\n",
       " 'Usaremos',\n",
       " 'la',\n",
       " 'biblioteca',\n",
       " 'nltk',\n",
       " '.',\n",
       " 'A',\n",
       " '.',\n",
       " 'C',\n",
       " '.',\n",
       " 'A',\n",
       " '.',\n",
       " 'M',\n",
       " '.',\n",
       " 'I',\n",
       " '.',\n",
       " 'C',\n",
       " '.',\n",
       " 'A',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer # TreebankWordTokenizer\n",
    "tokenizer=WordPunctTokenizer() # TreebankWordTokenizer\n",
    "tokenizer.tokenize(\"Bienvenid@s! En este módulo vamos a aprender sobre nlp. \\\n",
    "                    Usaremos la biblioteca nltk. A.C.A.M.I.C.A.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bienvenid',\n",
       " 's',\n",
       " 'En',\n",
       " 'este',\n",
       " 'módulo',\n",
       " 'vamos',\n",
       " 'a',\n",
       " 'aprender',\n",
       " 'sobre',\n",
       " 'nlp',\n",
       " 'Usaremos',\n",
       " 'la',\n",
       " 'biblioteca',\n",
       " 'nltk',\n",
       " 'A',\n",
       " 'C',\n",
       " 'A',\n",
       " 'M',\n",
       " 'I',\n",
       " 'C',\n",
       " 'A']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "tokenizer.tokenize(\"Bienvenid@s! En este módulo vamos a aprender sobre nlp. \\\n",
    "                    Usaremos la biblioteca nltk. A.C.A.M.I.C.A.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estamos modificando las letras\n",
      "ESTAMOS MODIFICANDO LAS LETRAS\n"
     ]
    }
   ],
   "source": [
    "text='ESTAmos ModIFICANDO lAS LETRas'\n",
    "print(text.lower())\n",
    "print(text.upper())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stops=set(stopwords.words('spanish'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estamos',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estaremos',\n",
       " 'estará',\n",
       " 'estarán',\n",
       " 'estarás',\n",
       " 'estaré',\n",
       " 'estaréis',\n",
       " 'estaría',\n",
       " 'estaríais',\n",
       " 'estaríamos',\n",
       " 'estarían',\n",
       " 'estarías',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'estemos',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuviéramos',\n",
       " 'estuviésemos',\n",
       " 'estuvo',\n",
       " 'está',\n",
       " 'estábamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'estás',\n",
       " 'esté',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estés',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'fuéramos',\n",
       " 'fuésemos',\n",
       " 'ha',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habremos',\n",
       " 'habrá',\n",
       " 'habrán',\n",
       " 'habrás',\n",
       " 'habré',\n",
       " 'habréis',\n",
       " 'habría',\n",
       " 'habríais',\n",
       " 'habríamos',\n",
       " 'habrían',\n",
       " 'habrías',\n",
       " 'habéis',\n",
       " 'había',\n",
       " 'habíais',\n",
       " 'habíamos',\n",
       " 'habían',\n",
       " 'habías',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'hayáis',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubiéramos',\n",
       " 'hubiésemos',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'más',\n",
       " 'mí',\n",
       " 'mía',\n",
       " 'mías',\n",
       " 'mío',\n",
       " 'míos',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'qué',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'sentid',\n",
       " 'sentida',\n",
       " 'sentidas',\n",
       " 'sentido',\n",
       " 'sentidos',\n",
       " 'seremos',\n",
       " 'será',\n",
       " 'serán',\n",
       " 'serás',\n",
       " 'seré',\n",
       " 'seréis',\n",
       " 'sería',\n",
       " 'seríais',\n",
       " 'seríamos',\n",
       " 'serían',\n",
       " 'serías',\n",
       " 'seáis',\n",
       " 'siente',\n",
       " 'sin',\n",
       " 'sintiendo',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'sí',\n",
       " 'también',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendremos',\n",
       " 'tendrá',\n",
       " 'tendrán',\n",
       " 'tendrás',\n",
       " 'tendré',\n",
       " 'tendréis',\n",
       " 'tendría',\n",
       " 'tendríais',\n",
       " 'tendríamos',\n",
       " 'tendrían',\n",
       " 'tendrías',\n",
       " 'tened',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tengáis',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'tenéis',\n",
       " 'tenía',\n",
       " 'teníais',\n",
       " 'teníamos',\n",
       " 'tenían',\n",
       " 'tenías',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuviéramos',\n",
       " 'tuviésemos',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'tú',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " 'él',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vamos', 'parque', 'sur', '?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Vamos al parque del sur?\"\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "[word for word in word_tokens if word not in stops]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'al',\n",
       " 'algo',\n",
       " 'algunas',\n",
       " 'algunos',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'como',\n",
       " 'con',\n",
       " 'contra',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'de',\n",
       " 'del',\n",
       " 'desde',\n",
       " 'donde',\n",
       " 'durante',\n",
       " 'e',\n",
       " 'el',\n",
       " 'ella',\n",
       " 'ellas',\n",
       " 'ellos',\n",
       " 'en',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'eras',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'esa',\n",
       " 'esas',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'esos',\n",
       " 'esta',\n",
       " 'estaba',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estabas',\n",
       " 'estad',\n",
       " 'estada',\n",
       " 'estadas',\n",
       " 'estado',\n",
       " 'estados',\n",
       " 'estamos',\n",
       " 'estando',\n",
       " 'estar',\n",
       " 'estaremos',\n",
       " 'estará',\n",
       " 'estarán',\n",
       " 'estarás',\n",
       " 'estaré',\n",
       " 'estaréis',\n",
       " 'estaría',\n",
       " 'estaríais',\n",
       " 'estaríamos',\n",
       " 'estarían',\n",
       " 'estarías',\n",
       " 'estas',\n",
       " 'este',\n",
       " 'estemos',\n",
       " 'esto',\n",
       " 'estos',\n",
       " 'estoy',\n",
       " 'estuve',\n",
       " 'estuviera',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuvieras',\n",
       " 'estuvieron',\n",
       " 'estuviese',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estuvieses',\n",
       " 'estuvimos',\n",
       " 'estuviste',\n",
       " 'estuvisteis',\n",
       " 'estuviéramos',\n",
       " 'estuviésemos',\n",
       " 'estuvo',\n",
       " 'está',\n",
       " 'estábamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'estás',\n",
       " 'esté',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estés',\n",
       " 'fue',\n",
       " 'fuera',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fueras',\n",
       " 'fueron',\n",
       " 'fuese',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'fueses',\n",
       " 'fui',\n",
       " 'fuimos',\n",
       " 'fuiste',\n",
       " 'fuisteis',\n",
       " 'fuéramos',\n",
       " 'fuésemos',\n",
       " 'ha',\n",
       " 'habida',\n",
       " 'habidas',\n",
       " 'habido',\n",
       " 'habidos',\n",
       " 'habiendo',\n",
       " 'habremos',\n",
       " 'habrá',\n",
       " 'habrán',\n",
       " 'habrás',\n",
       " 'habré',\n",
       " 'habréis',\n",
       " 'habría',\n",
       " 'habríais',\n",
       " 'habríamos',\n",
       " 'habrían',\n",
       " 'habrías',\n",
       " 'habéis',\n",
       " 'había',\n",
       " 'habíais',\n",
       " 'habíamos',\n",
       " 'habían',\n",
       " 'habías',\n",
       " 'han',\n",
       " 'has',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'haya',\n",
       " 'hayamos',\n",
       " 'hayan',\n",
       " 'hayas',\n",
       " 'hayáis',\n",
       " 'he',\n",
       " 'hemos',\n",
       " 'hube',\n",
       " 'hubiera',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubieras',\n",
       " 'hubieron',\n",
       " 'hubiese',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'hubieses',\n",
       " 'hubimos',\n",
       " 'hubiste',\n",
       " 'hubisteis',\n",
       " 'hubiéramos',\n",
       " 'hubiésemos',\n",
       " 'hubo',\n",
       " 'la',\n",
       " 'las',\n",
       " 'le',\n",
       " 'les',\n",
       " 'lo',\n",
       " 'los',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'mucho',\n",
       " 'muchos',\n",
       " 'muy',\n",
       " 'más',\n",
       " 'mí',\n",
       " 'mía',\n",
       " 'mías',\n",
       " 'mío',\n",
       " 'míos',\n",
       " 'nada',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nosotras',\n",
       " 'nosotros',\n",
       " 'nuestra',\n",
       " 'nuestras',\n",
       " 'nuestro',\n",
       " 'nuestros',\n",
       " 'o',\n",
       " 'os',\n",
       " 'otra',\n",
       " 'otras',\n",
       " 'otro',\n",
       " 'otros',\n",
       " 'para',\n",
       " 'pero',\n",
       " 'poco',\n",
       " 'por',\n",
       " 'porque',\n",
       " 'que',\n",
       " 'quien',\n",
       " 'quienes',\n",
       " 'qué',\n",
       " 'se',\n",
       " 'sea',\n",
       " 'seamos',\n",
       " 'sean',\n",
       " 'seas',\n",
       " 'sentid',\n",
       " 'sentida',\n",
       " 'sentidas',\n",
       " 'sentido',\n",
       " 'sentidos',\n",
       " 'seremos',\n",
       " 'será',\n",
       " 'serán',\n",
       " 'serás',\n",
       " 'seré',\n",
       " 'seréis',\n",
       " 'sería',\n",
       " 'seríais',\n",
       " 'seríamos',\n",
       " 'serían',\n",
       " 'serías',\n",
       " 'seáis',\n",
       " 'siente',\n",
       " 'sin',\n",
       " 'sintiendo',\n",
       " 'sobre',\n",
       " 'sois',\n",
       " 'somos',\n",
       " 'son',\n",
       " 'soy',\n",
       " 'su',\n",
       " 'sus',\n",
       " 'suya',\n",
       " 'suyas',\n",
       " 'suyo',\n",
       " 'suyos',\n",
       " 'sí',\n",
       " 'también',\n",
       " 'tanto',\n",
       " 'te',\n",
       " 'tendremos',\n",
       " 'tendrá',\n",
       " 'tendrán',\n",
       " 'tendrás',\n",
       " 'tendré',\n",
       " 'tendréis',\n",
       " 'tendría',\n",
       " 'tendríais',\n",
       " 'tendríamos',\n",
       " 'tendrían',\n",
       " 'tendrías',\n",
       " 'tened',\n",
       " 'tenemos',\n",
       " 'tenga',\n",
       " 'tengamos',\n",
       " 'tengan',\n",
       " 'tengas',\n",
       " 'tengo',\n",
       " 'tengáis',\n",
       " 'tenida',\n",
       " 'tenidas',\n",
       " 'tenido',\n",
       " 'tenidos',\n",
       " 'teniendo',\n",
       " 'tenéis',\n",
       " 'tenía',\n",
       " 'teníais',\n",
       " 'teníamos',\n",
       " 'tenían',\n",
       " 'tenías',\n",
       " 'ti',\n",
       " 'tiene',\n",
       " 'tienen',\n",
       " 'tienes',\n",
       " 'todo',\n",
       " 'todos',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'tuve',\n",
       " 'tuviera',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuvieras',\n",
       " 'tuvieron',\n",
       " 'tuviese',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'tuvieses',\n",
       " 'tuvimos',\n",
       " 'tuviste',\n",
       " 'tuvisteis',\n",
       " 'tuviéramos',\n",
       " 'tuviésemos',\n",
       " 'tuvo',\n",
       " 'tuya',\n",
       " 'tuyas',\n",
       " 'tuyo',\n",
       " 'tuyos',\n",
       " 'tú',\n",
       " 'un',\n",
       " 'una',\n",
       " 'uno',\n",
       " 'unos',\n",
       " 'vosotras',\n",
       " 'vosotros',\n",
       " 'vuestra',\n",
       " 'vuestras',\n",
       " 'vuestro',\n",
       " 'vuestros',\n",
       " 'y',\n",
       " 'ya',\n",
       " 'yo',\n",
       " 'él',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frecuencia de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "# Obtenemos el html de la página de acámica de Data Science\n",
    "response = urllib.request.urlopen('https://www.acamica.com/data-science')\n",
    "html = response.read()\n",
    "soup = BeautifulSoup(html,\"html5lib\")\n",
    "text = soup.get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizamos el resultado\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
    "word_tokens = tokenizer.tokenize(text)\n",
    "# Sacamos stopwords y convertimos en minúscula\n",
    "text_tokens = [word.lower() for word in word_tokens if word not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vamos:1\n",
      "parque:1\n",
      "sur:1\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la frecuencia de las palabras\n",
    "freq = nltk.FreqDist(text_tokens)\n",
    "sorted_by_value = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "for key,val in sorted_by_value:\n",
    "    print (str(key) + ':' + str(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('carrera', 'data')\n",
      "('data', 'science')\n",
      "('science', 'semipresencial')\n",
      "('semipresencial', 'acámica')\n",
      "('acámica', 'carrera')\n",
      "('carrera', 'semipresencialdata')\n",
      "('semipresencialdata', 'scienceaprendé')\n",
      "('scienceaprendé', 'manipular')\n",
      "('manipular', 'infinita')\n",
      "('infinita', 'cantidad')\n",
      "('cantidad', 'datos')\n",
      "('datos', 'alcance')\n",
      "('alcance', 'crear')\n",
      "('crear', 'impacto')\n",
      "('impacto', 'en')\n",
      "('en', 'colaboración')\n",
      "('colaboración', 'conaplica')\n",
      "('conaplica', 'ahora')\n",
      "('ahora', 'información')\n",
      "('información', 'carrera')\n",
      "('carrera', 'información')\n",
      "('información', 'carreralos')\n",
      "('carreralos', 'datos')\n",
      "('datos', 'petróleo')\n",
      "('petróleo', 'siglo')\n",
      "('siglo', 'xxihoy')\n",
      "('xxihoy', 'día')\n",
      "('día', 'capacidad')\n",
      "('capacidad', 'producir')\n",
      "('producir', 'almacenar')\n",
      "('almacenar', 'infinitas')\n",
      "('infinitas', 'cantidades')\n",
      "('cantidades', 'información')\n",
      "('información', 'distintas')\n",
      "('distintas', 'fuentes')\n",
      "('fuentes', 'sea')\n",
      "('sea', 'fotos')\n",
      "('fotos', 'reportes')\n",
      "('reportes', 'ventas')\n",
      "('ventas', 'códigos')\n",
      "('códigos', 'adn')\n",
      "('adn', 'dilema')\n",
      "('dilema', 'cómo')\n",
      "('cómo', 'usamos')\n",
      "('usamos', 'gigante')\n",
      "('gigante', 'cantidad')\n",
      "('cantidad', 'datos')\n",
      "('datos', 'crear')\n",
      "('crear', 'impacto')\n",
      "('impacto', 'en')\n",
      "('en', 'carrera')\n",
      "('carrera', 'vas')\n",
      "('vas', 'adquirir')\n",
      "('adquirir', 'skills')\n",
      "('skills', 'necesarios')\n",
      "('necesarios', 'recopilar')\n",
      "('recopilar', 'procesar')\n",
      "('procesar', 'analizar')\n",
      "('analizar', 'datos')\n",
      "('datos', 'luego')\n",
      "('luego', 'interpretarlos')\n",
      "('interpretarlos', 'realizar')\n",
      "('realizar', 'predicciones')\n",
      "('predicciones', 'automáticas')\n",
      "('automáticas', 'forma')\n",
      "('forma', 'inteligente')\n",
      "('inteligente', 'duración')\n",
      "('duración', '6')\n",
      "('6', 'mesesmodalidad')\n",
      "('mesesmodalidad', 'semipresencialcarga')\n",
      "('semipresencialcarga', 'horaria')\n",
      "('horaria', '14')\n",
      "('14', 'hs')\n",
      "('hs', 'semananivel')\n",
      "('semananivel', 'inicialaplica')\n",
      "('inicialaplica', 'ahora')\n",
      "('ahora', 'ver')\n",
      "('ver', 'plan')\n",
      "('plan', 'estudios')\n",
      "('estudios', 'en')\n",
      "('en', '6')\n",
      "('6', 'meses')\n",
      "('meses', 'vas')\n",
      "('vas', 'aprender')\n",
      "('aprender', 'demachine')\n",
      "('demachine', 'learningmachine')\n",
      "('learningmachine', 'learning')\n",
      "('learning', 'cimientos')\n",
      "('cimientos', 'inteligencia')\n",
      "('inteligencia', 'artificial')\n",
      "('artificial', 'permite')\n",
      "('permite', 'predecir')\n",
      "('predecir', 'comportamientos')\n",
      "('comportamientos', 'futuros')\n",
      "('futuros', 'través')\n",
      "('través', 'identificación')\n",
      "('identificación', 'patrones')\n",
      "('patrones', 'complejos')\n",
      "('complejos', 'nlpel')\n",
      "('nlpel', 'procesamiento')\n",
      "('procesamiento', 'lenguaje')\n",
      "('lenguaje', 'natural')\n",
      "('natural', 'base')\n",
      "('base', 'análisis')\n",
      "('análisis', 'lenguaje')\n",
      "('lenguaje', 'humano')\n",
      "('humano', 'se')\n",
      "('se', 'utiliza')\n",
      "('utiliza', 'ejemplo')\n",
      "('ejemplo', 'desarrollo')\n",
      "('desarrollo', 'asistentes')\n",
      "('asistentes', 'voz')\n",
      "('voz', 'siri')\n",
      "('siri', 'alexa')\n",
      "('alexa', 'clusteringes')\n",
      "('clusteringes', 'lógica')\n",
      "('lógica', 'permite')\n",
      "('permite', 'separar')\n",
      "('separar', 'datos')\n",
      "('datos', 'grupos')\n",
      "('grupos', 'forma')\n",
      "('forma', 'automatizada')\n",
      "('automatizada', 'según')\n",
      "('según', 'relaciones')\n",
      "('relaciones', 'esto')\n",
      "('esto', 'representa')\n",
      "('representa', 'parte')\n",
      "('parte', 'hoy')\n",
      "('hoy', 'conocemos')\n",
      "('conocemos', 'inteligencia')\n",
      "('inteligencia', 'artificial')\n",
      "('artificial', 'deep')\n",
      "('deep', 'learningmodelos')\n",
      "('learningmodelos', 'computacionales')\n",
      "('computacionales', 'permiten')\n",
      "('permiten', 'procesar')\n",
      "('procesar', 'datos')\n",
      "('datos', 'varias')\n",
      "('varias', 'capas')\n",
      "('capas', 'usar')\n",
      "('usar', 'resultado')\n",
      "('resultado', 'input')\n",
      "('input', 'futuros')\n",
      "('futuros', 'procesos')\n",
      "('procesos', 'esto')\n",
      "('esto', 'permite')\n",
      "('permite', 'tener')\n",
      "('tener', 'autos')\n",
      "('autos', 'autocomandados')\n",
      "('autocomandados', 'inteligencia')\n",
      "('inteligencia', 'artificial')\n",
      "('artificial', 'juegos')\n",
      "('juegos', 'cloud')\n",
      "('cloud', 'a')\n",
      "('a', 'i')\n",
      "('i', 'saber')\n",
      "('saber', 'manejar')\n",
      "('manejar', 'herramientas')\n",
      "('herramientas', 'cloud')\n",
      "('cloud', 'watson')\n",
      "('watson', 'ibm')\n",
      "('ibm', 'va')\n",
      "('va', 'dar')\n",
      "('dar', 'acceso')\n",
      "('acceso', 'computadoras')\n",
      "('computadoras', 'alto')\n",
      "('alto', 'poder')\n",
      "('poder', 'procesamiento')\n",
      "('procesamiento', 'modelos')\n",
      "('modelos', 'inteligencia')\n",
      "('inteligencia', 'artificial')\n",
      "('artificial', 'programados')\n",
      "('programados', 'utilizar')\n",
      "('utilizar', 'proyectos')\n",
      "('proyectos', 'deploymentademás')\n",
      "('deploymentademás', 'correr')\n",
      "('correr', 'algoritmos')\n",
      "('algoritmos', 'vas')\n",
      "('vas', 'poder')\n",
      "('poder', 'crear')\n",
      "('crear', 'productos')\n",
      "('productos', 'publicarlos')\n",
      "('publicarlos', 'usuarios')\n",
      "('usuarios', 'puedan')\n",
      "('puedan', 'usarlos')\n",
      "('usarlos', 'proyectos')\n",
      "('proyectos', 'reales')\n",
      "('reales', 'mano')\n",
      "('mano', 'expertos')\n",
      "('expertos', 'realescreemos')\n",
      "('realescreemos', 'mejor')\n",
      "('mejor', 'manera')\n",
      "('manera', 'aprender')\n",
      "('aprender', 'convertirte')\n",
      "('convertirte', 'experto')\n",
      "('experto', 'creando')\n",
      "('creando', 'aplicaciones')\n",
      "('aplicaciones', 'lleven')\n",
      "('lleven', 'distintos')\n",
      "('distintos', 'temas')\n",
      "('temas', 'ciencia')\n",
      "('ciencia', 'datos')\n",
      "('datos', 'seguimiento')\n",
      "('seguimiento', 'personalizado')\n",
      "('personalizado', 'feedback')\n",
      "('feedback', 'mentores')\n",
      "('mentores', 'profesionales')\n",
      "('profesionales', 'industria')\n",
      "('industria', 'arrow_back')\n",
      "('arrow_back', 'arrow_forwardproyecto')\n",
      "('arrow_forwardproyecto', 'próximas')\n",
      "('próximas', 'comisiones')\n",
      "('comisiones', 'últimos')\n",
      "('últimos', 'cuposaplica')\n",
      "('cuposaplica', 'ahoraaplica')\n",
      "('ahoraaplica', 'ciudadcertificación')\n",
      "('ciudadcertificación', 'empresas')\n",
      "('empresas', 'confía')\n",
      "('confía', 'progreso')\n",
      "('progreso', 'esfuerzo')\n",
      "('esfuerzo', 'va')\n",
      "('va', 'mano')\n",
      "('mano', 'necesidades')\n",
      "('necesidades', 'industria')\n",
      "('industria', 'validación')\n",
      "('validación', 'referentes')\n",
      "('referentes', 'diseño')\n",
      "('diseño', 'carrera')\n",
      "('carrera', 'mentoría')\n",
      "('mentoría', 'personalizada')\n",
      "('personalizada', 'nuestros')\n",
      "('nuestros', 'mentores')\n",
      "('mentores', 'acompañarán')\n",
      "('acompañarán', 'evacuar')\n",
      "('evacuar', 'todas')\n",
      "('todas', 'dudas')\n",
      "('dudas', 'aprendizaje')\n",
      "('aprendizaje', 'modelos')\n",
      "('modelos', 'datos')\n",
      "('datos', 'reales')\n",
      "('reales', 'trabaja')\n",
      "('trabaja', 'proyectos')\n",
      "('proyectos', 'modelos')\n",
      "('modelos', 'datos')\n",
      "('datos', 'reales')\n",
      "('reales', 'múltiples')\n",
      "('múltiples', 'entregas')\n",
      "('entregas', 'iteraciones')\n",
      "('iteraciones', 'cuales')\n",
      "('cuales', 'revisarás')\n",
      "('revisarás', 'mentores')\n",
      "('mentores', 'clase')\n",
      "('clase', 'habilidades')\n",
      "('habilidades', 'humanas')\n",
      "('humanas', 'laborales')\n",
      "('laborales', 'entendemos')\n",
      "('entendemos', 'importancia')\n",
      "('importancia', 'trabajar')\n",
      "('trabajar', 'desarrollar')\n",
      "('desarrollar', 'habilidades')\n",
      "('habilidades', 'complementarias')\n",
      "('complementarias', 'destaques')\n",
      "('destaques', 'profesional')\n",
      "('profesional', 'cualquier')\n",
      "('cualquier', 'ámbito')\n",
      "('ámbito', 'closerecibir')\n",
      "('closerecibir', 'plan')\n",
      "('plan', 'estudiosnombre')\n",
      "('estudiosnombre', 'dirección')\n",
      "('dirección', 'email')\n",
      "('email', 'país')\n",
      "('país', 'residencia')\n",
      "('residencia', 'elige')\n",
      "('elige', 'paísregión')\n",
      "('paísregión', 'elige')\n",
      "('elige', 'región')\n",
      "('región', 'cúal')\n",
      "('cúal', 'objetivo')\n",
      "('objetivo', 'principal')\n",
      "('principal', 'aprendizaje')\n",
      "('aprendizaje', 'elige')\n",
      "('elige', 'motivocomenzar')\n",
      "('motivocomenzar', 'carrera')\n",
      "('carrera', 'laboral')\n",
      "('laboral', 'tecnologíacrecer')\n",
      "('tecnologíacrecer', 'profesionalmente')\n",
      "('profesionalmente', 'carrera')\n",
      "('carrera', 'actual')\n",
      "('actual', 'relacionada')\n",
      "('relacionada', 'tecnología')\n",
      "('tecnología', 'complementar')\n",
      "('complementar', 'carrera')\n",
      "('carrera', 'actual')\n",
      "('actual', 'relacionada')\n",
      "('relacionada', 'tecnología')\n",
      "('tecnología', 'crear')\n",
      "('crear', 'proyecto')\n",
      "('proyecto', 'emprendimiento')\n",
      "('emprendimiento', 'personalinterés')\n",
      "('personalinterés', 'temaotrocloserecibir')\n",
      "('temaotrocloserecibir', 'plan')\n",
      "('plan', 'estudiosrecibirás')\n",
      "('estudiosrecibirás', 'email')\n",
      "('email', 'próximos')\n",
      "('próximos', 'minutos')\n",
      "('minutos', 'plan')\n",
      "('plan', 'estudios')\n",
      "('estudios', 'información')\n",
      "('información', 'detallada')\n",
      "('detallada', 'carrera')\n",
      "('carrera', 'revisa')\n",
      "('revisa', 'bandeja')\n",
      "('bandeja', 'correo')\n",
      "('correo', 'incluyendo')\n",
      "('incluyendo', 'promociones')\n",
      "('promociones', 'correo')\n",
      "('correo', 'deseado')\n",
      "('deseado', 'aceptarclosecompleta')\n",
      "('aceptarclosecompleta', 'aplicacióntras')\n",
      "('aplicacióntras', 'aplicar')\n",
      "('aplicar', 'asesor')\n",
      "('asesor', 'aplicaciones')\n",
      "('aplicaciones', 'contactará')\n",
      "('contactará', 'avanzar')\n",
      "('avanzar', 'admisión')\n",
      "('admisión', 'nombre')\n",
      "('nombre', 'apellido')\n",
      "('apellido', 'dirección')\n",
      "('dirección', 'email')\n",
      "('email', 'teléfono')\n",
      "('teléfono', 'celular')\n",
      "('celular', 'referral')\n",
      "('referral', 'code')\n",
      "('code', 'tienes')\n",
      "('tienes', 'referral')\n",
      "('referral', 'code')\n",
      "('code', 'ingrésalo')\n",
      "('ingrésalo', 'aquí')\n",
      "('aquí', 'closeaplica')\n",
      "('closeaplica', 'ciudadcuando')\n",
      "('ciudadcuando', 'próximos')\n",
      "('próximos', 'abrir')\n",
      "('abrir', 'sede')\n",
      "('sede', 'ciudad')\n",
      "('ciudad', 'contactaremos')\n",
      "('contactaremos', 'avanzar')\n",
      "('avanzar', 'admisión')\n",
      "('admisión', 'nombre')\n",
      "('nombre', 'apellido')\n",
      "('apellido', 'dirección')\n",
      "('dirección', 'email')\n",
      "('email', 'teléfono')\n",
      "('teléfono', 'celular')\n",
      "('celular', 'país')\n",
      "('país', 'residencia')\n",
      "('residencia', 'elige')\n",
      "('elige', 'paísregión')\n",
      "('paísregión', 'elige')\n",
      "('elige', 'regióncloseaplicación')\n",
      "('regióncloseaplicación', 'recibidauno')\n",
      "('recibidauno', 'asesores')\n",
      "('asesores', 'académicos')\n",
      "('académicos', 'contactará')\n",
      "('contactará', 'avanzar')\n",
      "('avanzar', 'aplicación')\n",
      "('aplicación', 'aceptarcloseaplicación')\n",
      "('aceptarcloseaplicación', 'recibidacuando')\n",
      "('recibidacuando', 'próximos')\n",
      "('próximos', 'abrir')\n",
      "('abrir', 'comisión')\n",
      "('comisión', 'ciudad')\n",
      "('ciudad', 'contactaremos')\n",
      "('contactaremos', 'avanzar')\n",
      "('avanzar', 'aplicación')\n",
      "('aplicación', 'aceptarcarrerasdesarrollo')\n",
      "('aceptarcarrerasdesarrollo', 'web')\n",
      "('web', 'full')\n",
      "('full', 'stackdiseño')\n",
      "('stackdiseño', 'ux')\n",
      "('ux', 'uidata')\n",
      "('uidata', 'sciencemarketing')\n",
      "('sciencemarketing', 'digitalacámicablogtrabajoscontáctanosayudateléfonosargentina')\n",
      "('digitalacámicablogtrabajoscontáctanosayudateléfonosargentina', '0800')\n",
      "('0800', '333')\n",
      "('333', '1077buenos')\n",
      "('1077buenos', 'aires')\n",
      "('aires', '11')\n",
      "('11', '3504')\n",
      "('3504', '1601córdoba')\n",
      "('1601córdoba', '351')\n",
      "('351', '270')\n",
      "('270', '0873mar')\n",
      "('0873mar', 'plata')\n",
      "('plata', '223')\n",
      "('223', '555')\n",
      "('555', '5012')\n",
      "('5012', '2018')\n",
      "('2018', 'acámicatérminosprivacidad')\n",
      "('acámicatérminosprivacidad', 'function')\n",
      "('function', 'var')\n",
      "('var', 'analytics')\n",
      "('analytics', 'window')\n",
      "('window', 'analytics')\n",
      "('analytics', 'window')\n",
      "('window', 'analytics')\n",
      "('analytics', 'if')\n",
      "('if', 'analytics')\n",
      "('analytics', 'initialize')\n",
      "('initialize', 'if')\n",
      "('if', 'analytics')\n",
      "('analytics', 'invoked')\n",
      "('invoked', 'window')\n",
      "('window', 'console')\n",
      "('console', 'console')\n",
      "('console', 'error')\n",
      "('error', 'console')\n",
      "('console', 'error')\n",
      "('error', 'segment')\n",
      "('segment', 'snippet')\n",
      "('snippet', 'included')\n",
      "('included', 'twice')\n",
      "('twice', 'else')\n",
      "('else', 'analytics')\n",
      "('analytics', 'invoked')\n",
      "('invoked', '0')\n",
      "('0', 'analytics')\n",
      "('analytics', 'methods')\n",
      "('methods', 'tracksubmit')\n",
      "('tracksubmit', 'trackclick')\n",
      "('trackclick', 'tracklink')\n",
      "('tracklink', 'trackform')\n",
      "('trackform', 'pageview')\n",
      "('pageview', 'identify')\n",
      "('identify', 'reset')\n",
      "('reset', 'group')\n",
      "('group', 'track')\n",
      "('track', 'ready')\n",
      "('ready', 'alias')\n",
      "('alias', 'debug')\n",
      "('debug', 'page')\n",
      "('page', 'once')\n",
      "('once', 'off')\n",
      "('off', 'on')\n",
      "('on', 'analytics')\n",
      "('analytics', 'factory')\n",
      "('factory', 'function')\n",
      "('function', 't')\n",
      "('t', 'return')\n",
      "('return', 'function')\n",
      "('function', 'var')\n",
      "('var', 'array')\n",
      "('array', 'prototype')\n",
      "('prototype', 'slice')\n",
      "('slice', 'call')\n",
      "('call', 'arguments')\n",
      "('arguments', 'unshift')\n",
      "('unshift', 't')\n",
      "('t', 'analytics')\n",
      "('analytics', 'push')\n",
      "('push', 'return')\n",
      "('return', 'analytics')\n",
      "('analytics', 'for')\n",
      "('for', 'var')\n",
      "('var', 't')\n",
      "('t', '0')\n",
      "('0', 't')\n",
      "('t', 'analytics')\n",
      "('analytics', 'methods')\n",
      "('methods', 'length')\n",
      "('length', 't')\n",
      "('t', 'var')\n",
      "('var', 'analytics')\n",
      "('analytics', 'methods')\n",
      "('methods', 't')\n",
      "('t', 'analytics')\n",
      "('analytics', 'analytics')\n",
      "('analytics', 'factory')\n",
      "('factory', 'analytics')\n",
      "('analytics', 'load')\n",
      "('load', 'function')\n",
      "('function', 't')\n",
      "('t', 'var')\n",
      "('var', 'document')\n",
      "('document', 'createelement')\n",
      "('createelement', 'script')\n",
      "('script', 'type')\n",
      "('type', 'text')\n",
      "('text', 'javascript')\n",
      "('javascript', 'async')\n",
      "('async', '0')\n",
      "('0', 'src')\n",
      "('src', 'https')\n",
      "('https', 'document')\n",
      "('document', 'location')\n",
      "('location', 'protocol')\n",
      "('protocol', 'https')\n",
      "('https', 'http')\n",
      "('http', 'cdn')\n",
      "('cdn', 'segment')\n",
      "('segment', 'com')\n",
      "('com', 'analytics')\n",
      "('analytics', 'js')\n",
      "('js', 'v1')\n",
      "('v1', 't')\n",
      "('t', 'analytics')\n",
      "('analytics', 'min')\n",
      "('min', 'js')\n",
      "('js', 'var')\n",
      "('var', 'n')\n",
      "('n', 'document')\n",
      "('document', 'getelementsbytagname')\n",
      "('getelementsbytagname', 'script')\n",
      "('script', '0')\n",
      "('0', 'n')\n",
      "('n', 'parentnode')\n",
      "('parentnode', 'insertbefore')\n",
      "('insertbefore', 'n')\n",
      "('n', 'analytics')\n",
      "('analytics', 'snippet_version')\n",
      "('snippet_version', '4')\n",
      "('4', '0')\n",
      "('0', '0')\n",
      "('0', 'analytics')\n",
      "('analytics', 'load')\n",
      "('load', 'eg5r2nmaoprzxcmzubdalph0gtkughow')\n",
      "('eg5r2nmaoprzxcmzubdalph0gtkughow', 'analytics')\n",
      "('analytics', 'page')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "n = 2\n",
    "bigrams = ngrams(text_tokens, n)\n",
    "\n",
    "for grams in bigrams:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corr'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('correr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gato\n",
      "gatos\n",
      "ser\n"
     ]
    }
   ],
   "source": [
    "# Instalar pattern con pip install Pattern (necesita mysql como dependencia)\n",
    "from pattern.es import singularize, pluralize, conjugate\n",
    "\n",
    "print(singularize('gatos'))\n",
    "print(pluralize('gato'))\n",
    "print(conjugate('soy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el\n",
      "perro\n",
      "se\n",
      "esconder\n",
      "debajo\n",
      "del\n",
      "sofá\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from pattern.es import parsetree\n",
    "\n",
    "pt = parsetree('Los perros se esconden debajo del sofá.', lemmata=True)\n",
    "for sentence in pt: \n",
    "    for lemmata in sentence.lemmata: \n",
    "        print(lemmata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "asterion_text = 'Cada nueve años entran en la casa nueve hombres \\\n",
    "para que yo los libere de todo mal. Oigo sus pasos o su voz en el \\\n",
    "fondo de las galerías de piedra y corro alegremente a buscarlos. \\\n",
    "La ceremonia dura pocos minutos. Uno tras otro caen sin que yo me \\\n",
    "ensantgriente las manos. Donde cayeron, quedan, y los cadáveres ayudan\\\n",
    "a distinguir una galería de las otras. Ignoro quiénes son, pero sé que \\\n",
    "uno de ellos profetizó, en la hora de su muerte, que alguna vez llegaría \\\n",
    "mi redentor, Desde entonces no me duele la soledad, porque sé que vive mi \\\n",
    "redeentor y al fin se levantará sobre el polvo. Si mi oído alcanzara \\\n",
    "los rumores del mundo, yo percibiría sus pasos. Ojalá me lleve a un \\\n",
    "lugar con menos galerías y menos puertas. ¿Cómo será mi redentor?, me pregunto.\\\n",
    "¿Será un toro o un hombre? ¿Será tal vez un toro con cara de hombre? ¿O será como yo?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = sent_tokenize(asterion_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      "  0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]]\n",
      "{'cada': 7, 'nueve': 56, 'años': 5, 'entran': 30, 'en': 27, 'la': 39, 'casa': 11, 'hombres': 36, 'para': 62, 'que': 73, 'yo': 99, 'los': 45, 'libere': 42, 'de': 18, 'todo': 90, 'mal': 47, 'oigo': 57, 'sus': 87, 'pasos': 63, 'su': 86, 'voz': 98, 'el': 25, 'fondo': 32, 'las': 40, 'galerías': 34, 'piedra': 66, 'corro': 16, 'alegremente': 2, 'buscarlos': 6, 'ceremonia': 13, 'dura': 24, 'pocos': 67, 'minutos': 52, 'uno': 95, 'tras': 92, 'otro': 60, 'caen': 9, 'sin': 82, 'me': 49, 'ensantgriente': 28, 'manos': 48, 'donde': 22, 'cayeron': 12, 'quedan': 74, 'cadáveres': 8, 'ayudana': 4, 'distinguir': 21, 'una': 94, 'galería': 33, 'otras': 59, 'ignoro': 38, 'quiénes': 75, 'son': 85, 'pero': 65, 'sé': 88, 'ellos': 26, 'profetizó': 71, 'hora': 37, 'muerte': 53, 'alguna': 3, 'vez': 96, 'llegaría': 43, 'mi': 51, 'redentor': 77, 'desde': 20, 'entonces': 29, 'no': 55, 'duele': 23, 'soledad': 84, 'porque': 69, 'vive': 97, 'redeentor': 76, 'al': 0, 'fin': 31, 'se': 79, 'levantará': 41, 'sobre': 83, 'polvo': 68, 'si': 81, 'oído': 61, 'alcanzara': 1, 'rumores': 78, 'del': 19, 'mundo': 54, 'percibiría': 64, 'ojalá': 58, 'lleve': 44, 'un': 93, 'lugar': 46, 'con': 15, 'menos': 50, 'puertas': 72, 'cómo': 17, 'será': 80, 'pregunto': 70, 'toro': 91, 'hombre': 35, 'tal': 89, 'cara': 10, 'como': 14}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "print(vectorizer.fit_transform(corpus).todense()[0])\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.30151134  0.\n",
      "   0.30151134  0.          0.          0.          0.30151134  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.30151134  0.          0.          0.          0.          0.\n",
      "   0.30151134  0.          0.          0.          0.30151134  0.          0.\n",
      "   0.          0.30151134  0.          0.          0.          0.          0.\n",
      "   0.60302269  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]]\n",
      "{'cada': 6, 'nueve': 40, 'años': 4, 'entran': 20, 'casa': 10, 'hombres': 26, 'libere': 30, 'mal': 34, 'oigo': 41, 'pasos': 44, 'voz': 65, 'fondo': 22, 'galerías': 24, 'piedra': 46, 'corro': 13, 'alegremente': 1, 'buscarlos': 5, 'ceremonia': 12, 'dura': 17, 'pocos': 47, 'minutos': 37, 'tras': 62, 'caen': 8, 'ensantgriente': 18, 'manos': 35, 'cayeron': 11, 'quedan': 52, 'cadáveres': 7, 'ayudana': 3, 'distinguir': 15, 'galería': 23, 'ignoro': 28, 'quiénes': 53, 'sé': 59, 'profetizó': 50, 'hora': 27, 'muerte': 38, 'alguna': 2, 'vez': 63, 'llegaría': 31, 'redentor': 55, 'entonces': 19, 'duele': 16, 'soledad': 58, 'vive': 64, 'redeentor': 54, 'fin': 21, 'levantará': 29, 'polvo': 48, 'si': 57, 'oído': 43, 'alcanzara': 0, 'rumores': 56, 'mundo': 39, 'percibiría': 45, 'ojalá': 42, 'lleve': 32, 'lugar': 33, 'menos': 36, 'puertas': 51, 'cómo': 14, 'pregunto': 49, 'toro': 61, 'hombre': 25, 'tal': 60, 'cara': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stops)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus) \n",
    "print(tfidf_matrix.todense()[0])\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.0788901 ,  0.        ,  0.        ,  1.        ,  0.34859007,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(tfidf_matrix[8], tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Cómo será mi redentor?, me pregunto.¿Será un toro o un hombre?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cada nueve años entran en la casa nueve hombres para que yo los libere de todo mal.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
